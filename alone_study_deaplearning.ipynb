{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNY0GRKBaUbaqKSmRHl0zdE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yooburi/alone_DL_study/blob/main/alone_study_deaplearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 혼자 공부하는 머신러닝+딥러닝\n"
      ],
      "metadata": {
        "id": "ToVtkJZBN9Cj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\\\n",
        "## Chapter 1-3 마켓과 머신러닝\n",
        "목표: 생선 이름을 자동으로 알려주는 머신 러닝을 만들어라.\n",
        "\n",
        "KNN 알고리즘\n"
      ],
      "metadata": {
        "id": "iV_dAhexObA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#35마리의 도미 데이터 준비하기.\n",
        "\n",
        "bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0,\n",
        "                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0,\n",
        "                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]\n",
        "bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0,\n",
        "                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0,\n",
        "                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]"
      ],
      "metadata": {
        "id": "vOl89y6KP2Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "matplotlib을 사용하면 데이터를 그래프로 시각화할 수 있다.\n",
        "\n",
        "파이썬에서 과학계산용 그래프를 그리는 라이브러리.\n",
        "\n",
        "산점도 그래프가 일직선에 가까운 형태를 **선형적**이라고 말함."
      ],
      "metadata": {
        "id": "kBVsIlJzRBIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(bream_length, bream_weight)\n",
        "plt.xlabel('length') #x축은 길이\n",
        "plt.ylabel('weight') #y축은 무게\n",
        "plt.show() #2차원 그래프"
      ],
      "metadata": {
        "id": "Dvuyr2KAQh9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 빙어 데이터 준비하기 14마리 빙어.\n",
        "\n",
        "smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]\n",
        "smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]\n",
        "\n",
        "plt.scatter(bream_length, bream_weight)\n",
        "plt.scatter(smelt_length, smelt_weight)\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m4BJcmBHRdIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\\\n",
        "### K-Nearest Neighbors/K-최근접 이웃 알고리즘\n",
        "\n"
      ],
      "metadata": {
        "id": "BXx6T75-SZJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "해당 알고리즘을 사용하기 전에 준비한 도미와 방어 데이터를 하나의 데이터로 합치기.\n",
        "\n",
        "파이썬에서 두개의 리스트를 더하면 하나의 리스트가 된다."
      ],
      "metadata": {
        "id": "SaYpwZJQTViE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length = bream_length + smelt_length\n",
        "weight = bream_weight + smelt_weight"
      ],
      "metadata": {
        "id": "IyJJ2vCoS2IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신러닝 패키지인 사이킷런을 사용할 것이다.\n",
        "\n",
        "패키지를 사용하려면 각 특성의 리스트를 세로 방향으로 늘어뜨린 **2차원 리스트**를 만들어야 한다.\n",
        "\n",
        "zip()함수와 리스트 구문을 사용하여 length와 weight를 2차원 리스트로 만들기"
      ],
      "metadata": {
        "id": "yEvcGFbsTUAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fish_data = [[l,w] for l,w in zip(length, weight)]\n",
        "print(fish_data) #49마리의 생선 데이터(2차원 리스트)"
      ],
      "metadata": {
        "id": "nq2qLz4ST32p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "49개의 학습(입력)데이터를 모두 준비했다면 정답 데이터를 준비.\n",
        "\n",
        "도미는 1 빙어는 0으로 표현한다면..."
      ],
      "metadata": {
        "id": "Vpd5IMuxUmhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fish_target = [1] * 35 + [0] * 14\n",
        "print(fish_target)"
      ],
      "metadata": {
        "id": "5iJ99ztxVD_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "사이킷런 패키지의 **k-최근접 이웃 알고리즘**을 구현한 클래스인 KNeighborsClassifier 사용."
      ],
      "metadata": {
        "id": "rGWcvqCjXKHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#KNeighborsClassifier 클래스의 객체를 만들기\n",
        "kn = KNeighborsClassifier()"
      ],
      "metadata": {
        "id": "INzSLIL4Xk6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 객체에 fish_data와 fish_target을 전달하여 도미를 찾기 위한 기준을 학습시킨다. 이런 과정을 머신러닝에서는 **훈련**이라고 부른다. **fit()메소드가 학습 역할을 한다.**"
      ],
      "metadata": {
        "id": "wxeqrorMX0T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 시키는 과정. train\n",
        "kn.fit(fish_data, fish_target)"
      ],
      "metadata": {
        "id": "qYRoSdcWYPum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#얼마나 잘 훈련되었는지 평가\n",
        "kn.score(fish_data, fish_target)"
      ],
      "metadata": {
        "id": "9pGQOukPY74B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> k-최근접 이웃 알고리즘은 **어떤 데이터에 대한 답을 구할 때 주위의 데이터를 보고 다수를 차지하는 것을 정답으로 사용**한다. 즉, 주위의 데이터로 현재 데이터를 판단하는 것.\n",
        "\n",
        "kn.predict를 통해 새로운 데이터의 정답을 예측할 수도 있다."
      ],
      "metadata": {
        "id": "5kk5MRbwZIxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kn.predict([[30,600]])"
      ],
      "metadata": {
        "id": "vQBEGXqwZ27Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **k-최근접 이웃 알고리즘의 한계**\n",
        "\n",
        "데이터가 아주 많은 경우 사용하기 어렵다. 데이터가 크기 때문에 메모리가 많이 필요하고 직선거리를 계산하는데 많은 시간이 필요하다.\n",
        "\n",
        "그리고 실제로 이 알고리즘은 무언가 훈련되는것이 없는 셈이다. 학습 데이터를 모두 저장하고 있다가 새로운 데이터가 등장하면 가장 가까운 데이터를 참고하여 구분한다. **가까운 몇 개의 데이터를 참고하느냐에 따라(매개변수) 성능이 달라지게 된다.**\n",
        "\n",
        "기본값은 5인데 49개로 하는경우.."
      ],
      "metadata": {
        "id": "-EfFr0fWaI17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kn49 = KNeighborsClassifier(n_neighbors=49)\n",
        "kn49.fit(fish_data, fish_target)\n",
        "kn49.score(fish_data, fish_target)"
      ],
      "metadata": {
        "id": "h8bCd-GlbPe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\\\n",
        "### Summary\n",
        "\n",
        "KNN 알고리즘은 가장 간단한 머신러닝 알고리즘.\n",
        "\n",
        "사실 어떤 규칙을 찾는다기 보다는 전체 데이터를 메모리에 가지고 있고 새로운 데이터와 비교하는 것이 전부.\n",
        "\n",
        "\\\n",
        "[scikit-learn]\n",
        "\n",
        "KNeighborsClassifier(): k-최근접 이웃 분류 모델 만드는 클래스\\\n",
        "fit(): 사이킷런 모델을 훈련\\\n",
        "predict(): 사이킷런 모델을 훈련하고 예측\\\n",
        "score(): 훈련된 사이킷런 모델의 성능을 측정.\n"
      ],
      "metadata": {
        "id": "kce2soMXcEdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mission: n_neighbors 늘려가며 score가 낮아지기 시작하는 지점을 찾기.\n",
        "for n in range(5,50):\n",
        "    # k-최근접 이웃 개수 설정\n",
        "    kn.n_neighbors = kn.n_neighbors + 1\n",
        "\n",
        "    #점수 계산\n",
        "    score = kn.score(fish_data, fish_target)\n",
        "\n",
        "    if score <1:\n",
        "      print(n, score)\n",
        "      break"
      ],
      "metadata": {
        "id": "q5-cEIoIdwwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\\\n",
        "\n",
        "##Chapter 2-1 훈련세트와 테스트 세트"
      ],
      "metadata": {
        "id": "UZgaOKmQfVKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신 러닝의 알고리즘은 크게 지도 학습과 비지도 학습으로 나눌 수 있다.\n",
        "\n",
        "\\\n",
        "- 지도 학습 \\\n",
        "지도 학습 알고리즘은 훈련하기 위한 **데이터와 정답**이 필요하다. \\\n",
        " **데이터와 정답을 input과 target이라고 하고 이를 합쳐 훈련 데이터**라고 부른다. 입력으로 사용된 길이와 무게를 **특성(feature)**이라고 한다.\n",
        "\n",
        "- 비지도 학습 \\\n",
        "정답 타깃 없이 입력 데이터만 사용하는 알고리즘"
      ],
      "metadata": {
        "id": "koPuirTagtzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\\\n",
        "\n",
        "### 훈련 세트와 테스트 세트\n",
        "\n",
        "머신러닝 알고리즘의 성능을 제대로 평가하려면 훈련 데이터와 평가에 사용할 데이터가 각각 달라야 한다.\n",
        "\n",
        "**훈련에 사용한 데이터로 모델을 평가하는 것은 적절하지 않은 방식.** 보통은 훈련 데이터의 일부를 떼어 테스트 세트로 사용한다."
      ],
      "metadata": {
        "id": "L8WdBKDXM2sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0,\n",
        "                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0,\n",
        "                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8,\n",
        "                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]\n",
        "fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0,\n",
        "                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0,\n",
        "                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7,\n",
        "                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]\n",
        "\n",
        "#두 생선 길이와 무게에 대한 리스트를 2차원 리스트로 만듦.\n",
        "fish_data = [[l,w] for l, w in zip(fish_length, fish_weight)]\n",
        "fish_target = [1] * 35 + [0] * 14"
      ],
      "metadata": {
        "id": "i_u4JhUeNv10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하나의 생선 데이터를 샘플이라고 한다. 도미 35샘플, 빙어 14샘플이 있는 상태. 각 샘플에 사용하는 특성은 길이와 무게 2개.\n",
        "\n",
        "처음 데이터 35개를 훈련, 나머지 14개를 테스트 세트로 사용해보자."
      ],
      "metadata": {
        "id": "XR5uZReBOR-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "kn = KNeighborsClassifier()"
      ],
      "metadata": {
        "id": "NGyZYtNcOclS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이썬의 슬라이싱을 사용.\n",
        "\n",
        "마지막 인덱스는 포함되지 않는 것에 유의하자."
      ],
      "metadata": {
        "id": "HugBHH-DOnvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input = fish_data[:35]\n",
        "train_target = fish_target[:35]\n",
        "test_input = fish_data[35:]\n",
        "test_target = fish_target[35:]\n",
        "\n",
        "kn = kn.fit(train_input, train_target)\n",
        "kn.score(test_input, test_target)"
      ],
      "metadata": {
        "id": "L9YkSWU4O0nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 성능을 나타내는 score값이 0이다. 문제는 샘플링 편향.\n",
        "\n",
        "**훈련 세트와 테스트 세트를 나누려면 데이터들이 골고루 섞이게 만들어야 한다.**\n",
        "\n",
        "---\n",
        "\\\n",
        "**Numpy**\n",
        "\n",
        "파이썬의 리스트로 2차원 리스트를 표현할 수 있지만 고차원 리스트를 표현하기에는 매우 번거롭다.\n",
        "\n",
        "파이썬 리스트를 numpy 배열로 바꾸는 것은 정말 쉽다. numpy의 array()함수에 파이썬 리스트를 전달하면 끝이다.\n"
      ],
      "metadata": {
        "id": "KMv1E3KXPS3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "input_arr = np.array(fish_data)\n",
        "target_arr = np.array(fish_target)\n",
        "\n",
        "#print(input_arr)\n",
        "print(input_arr.shape) #배열의 크기를 알려줌. (샘플, 특성 수)"
      ],
      "metadata": {
        "id": "ZSREEjhDQGU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 편향성을 없애주기 위해 무작위로 샘플을 고르는 방식을 선택해보자.\n",
        "\n",
        "주의해야할 점은 input_arr와 target_arr에서 같은 위치는 함께 선택되어야 한다는 점이다.\n",
        "\n",
        " 아예 인덱스를 섞은 다음 input_arr와 target_arr에서 샘플을 선택하면 무작위로 나누는 셈이 된다."
      ],
      "metadata": {
        "id": "lAavslT5QxRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "index = np.arange(49)\n",
        "np.random.shuffle(index)\n",
        "\n",
        "print(index) #랜덤한 순서로 인덱스 생성."
      ],
      "metadata": {
        "id": "eL-1raC2Uevp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "numpy의 arange()함수에 정수 N을 전달하면 0에서부터 N-1까지 1씩 증가하는 배열을 만든다.\n",
        "\n",
        "random 패키지 아래에 있는 shuffle() 함수는 주어진 배열을 무작위로 섞는다. **즉, 인덱스가 들어있는 리스트**\n",
        "\n",
        "***numpy 배열을 인덱스로 전달할 수 있다.***"
      ],
      "metadata": {
        "id": "rMXlWLE5U6cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input = input_arr[index[:35]]\n",
        "train_target = target_arr[index[:35]]\n",
        "test_input = input_arr[index[35:]]\n",
        "test_target = target_arr[index[35:]]\n",
        "\n",
        "print(input_arr[13], train_input[0])"
      ],
      "metadata": {
        "id": "8A1RX_FnWklo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***train_input의 첫 번째 원소는 input_arr의 열 네 번째 원소가 들어 있을 것이다.***"
      ],
      "metadata": {
        "id": "3zcHizrlXMcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(train_input[:,0], train_input[:,1])\n",
        "plt.scatter(test_input[:,0], test_input[:,1])\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2CAJcCK-X4V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시각화해보면 랜덤하게 섞여 있는 것을 볼 수 있다. 이 데이터들로 훈련을 시켜보면.."
      ],
      "metadata": {
        "id": "pjAZw--xYGSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kn = kn.fit(train_input, train_target)\n",
        "kn.score(test_input, test_target)"
      ],
      "metadata": {
        "id": "VnSfo64_YNtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.0이 나왔다면 100%의 확률로 테스트 세트에 있는 모든 생선을 맞췄다는 것이다.**\n",
        "\n",
        "predict()로 테스트 세트의 예측 결과와 실제 타깃을 확인해보자. 참고로 결과로 나오는 array는 모두 numpy 배열이다."
      ],
      "metadata": {
        "id": "vEryJVeRYVEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kn.predict(test_input)"
      ],
      "metadata": {
        "id": "fYdmFxwrYnS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g0RqCc2cZUkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\\\n",
        "\n",
        "### Summary\n",
        "**지도 학습**: 입력과 타깃을 전달하여 모델을 학습시킨 다음 새로운 데이터로 예측하는 과정. KNN도 지도 학습 알고리즘이다.\n",
        "\n",
        "**비지도 학습**: 타깃 데이터가 없음. 즉, 정답이 없음. 입력 데이터에서 어떤 특징을 찾는 데 주로 활용한다.\n",
        "\n",
        "**훈련 세트**: 클수록 좋다.\n",
        "\n",
        "\\\n",
        "\n",
        "올바른 학습을 시키기 위해서는 훈련 세트와 테스트 세트로 나누어야 한다. 샘플링할 때는 데이터가 편향되면 안되고 랜덤하게 골고루 있어야 한다.\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "* numpy arange(): 일정한 간격의 정수 또는 실수 배열을 만든다. 기본 간격은 1. 매개변수가 3개면 마지막 매개변수가 간격을 나타낸다."
      ],
      "metadata": {
        "id": "_91EKHVeZVh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\\\n",
        "##Chapter 2-2 데이터 전처리\n"
      ],
      "metadata": {
        "id": "GXoe4eZxbE_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "우선 기존 리스트가 아닌 넘파이로 데이터를 준비해보자."
      ],
      "metadata": {
        "id": "hB0nZ_0Jc1V8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0,\n",
        "                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0,\n",
        "                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8,\n",
        "                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]\n",
        "fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0,\n",
        "                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0,\n",
        "                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7,\n",
        "                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]"
      ],
      "metadata": {
        "id": "Hi7sm1LBbdub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전에는 이 파이썬 리스트를 순회하면서 원소를 하나씩 꺼내 생선 하나의 길이와 무게를 리스트 안의 리스트로 직접 구성하였다. numpy를 사용하면 엄청 간단하게 가능하다!"
      ],
      "metadata": {
        "id": "3hJhyzFCbm5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "fish_data = np.column_stack((fish_length, fish_weight))\n",
        "\n",
        "print(fish_data[:5])\n",
        "\n",
        "print(fish_data.shape)"
      ],
      "metadata": {
        "id": "ETPpv6d5bw37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "넘파이의 column_stack()은 전달받은 리스트를 일렬로 세운 다음 차례대로 나란히 연결한다.\n",
        "\n",
        "target(정답) 데이터도 넘파이를 통해 간단하게 만들 수 있다."
      ],
      "metadata": {
        "id": "99DWZyuhcRpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fish_target = np.concatenate((np.ones(35),np.zeros(14)))\n",
        "\n",
        "print(fish_target)\n",
        "print(fish_target.shape)"
      ],
      "metadata": {
        "id": "xSByiAKgdTR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "concatenate()은 전달받은 리스트를 1차원으로 연결해준다.\n",
        "\n",
        "\\\n",
        "\n",
        "이제 사이킷런을 이용하여 훈련 세트와 테스트 세트를 나누어보자.\n",
        "\n",
        "기존에 인덱스를 직접 섞어 썼다면 train_test_split()를 이용하여 쉽게 나눌 수 있다. 기본적으로 25%를 테스트 세트로 떼어 낸다."
      ],
      "metadata": {
        "id": "4gI5mZG-dn-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(fish_data, fish_target, random_state=42)\n",
        "\n",
        "print(train_input.shape, test_input.shape)\n",
        "print(train_target.shape, test_target.shape)\n",
        "\n",
        "#도미와 빙어가 잘 섞였는지..\n",
        "print(test_target)"
      ],
      "metadata": {
        "id": "9gOsIh9meIEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "잘 섞여있지 않은 것을 알 수 있다. 일부 클래스의 개수가 적을 때 이런 일이 발생할 수 있다.\n",
        "\n",
        "**stratify 매개변수에 target 데이터를 전달하면 클래스 비율에 맞게 데이터를 나눈다.**"
      ],
      "metadata": {
        "id": "ec6pTdDte6t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input, test_input, train_target, test_target = train_test_split(fish_data, fish_target, stratify=fish_target , random_state=42)\n",
        "\n",
        "#클래스의 비율에 맞아졌다.\n",
        "print(test_target)"
      ],
      "metadata": {
        "id": "kLaKM6erfSEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\\\n",
        "\n",
        "KNN 알고리즘을 이용한 학습\n"
      ],
      "metadata": {
        "id": "S7lAhhZ7ffY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "kn = KNeighborsClassifier()\n",
        "kn.fit(train_input, train_target)\n",
        "kn.score(test_input, test_target)"
      ],
      "metadata": {
        "id": "3FHtmTnefpw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습이 잘 되었지만 애매한 도미를 잡지 못함.\n",
        "print(kn.predict([[25,150]]))"
      ],
      "metadata": {
        "id": "XE-NQA87f200"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다른 데이터들과 함께 matplot해보면.."
      ],
      "metadata": {
        "id": "g8SsaDFDgEug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(train_input[:,0], train_input[:,1])\n",
        "plt.scatter(25,150, marker='^')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X7MgPGImgIgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN 알고리즘은 기본적으로 가까운 5개의 데이터를 기준으로 판단하는데 새로운 데이터에 대해 빙어가 더 가깝다."
      ],
      "metadata": {
        "id": "AjFMUBb_gi9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distances, indexes = kn.kneighbors([[25,150]]) # 훈련 데이터 중 이웃 샘플 인덱스 저장\n",
        "\n",
        "plt.scatter(train_input[:,0], train_input[:,1])\n",
        "plt.scatter(25,150, marker='^')\n",
        "plt.scatter(train_input[indexes,0], train_input[indexes,1], marker='D')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()\n",
        "\n",
        "print(train_input[indexes])\n",
        "print(train_target[indexes])\n",
        "print(distances)\n",
        "\n",
        "plt.scatter(train_input[:,0], train_input[:,1])\n",
        "plt.scatter(25,150, marker='^')\n",
        "plt.scatter(train_input[indexes,0], train_input[indexes,1], marker='D')\n",
        "plt.xlim((0,1000))\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3AD83VUeguay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**x축과 y축의 scale이 현저하게 달라서 알고리즘이 올바르게 예측할 수가 없다.**\n",
        "\n",
        "특히 거리 기반인 경우 샘플 간 거리에 영향을 많이 받게 되므로 제대로 사용하려면 특성값을 일정한 기준으로 맞춰 주어야 한다."
      ],
      "metadata": {
        "id": "1VixmomthgUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리\n",
        "\n",
        "가장 널리 사용하는 전처리 방법 중 하나는 '표준점수'\n",
        "\n",
        "고등학교 때 배웠던 분산과 표준편자 개념이다. 평균에서 얼마나 떨어져 있는지 나타내는 척도."
      ],
      "metadata": {
        "id": "h3rfvrW5iIIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(train_input, axis=0) # 평균 계산\n",
        "std = np.std(train_input, axis=0) # 표준편차 계산\n",
        "\n",
        "print(mean, std)"
      ],
      "metadata": {
        "id": "NLte_iH1F59t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "특성마다 값의 스케일이 다르므로 평균과 표준편차는 각 특성별로 계산해야 한다. 그래서 axis=0으로 지정.\n",
        "\n",
        "**train_input의 경우 (36,2) 배열인데 axis=0이므로 두 줄에 대한 평균과 표준편차를 계산한 것.**"
      ],
      "metadata": {
        "id": "TBJe_dxWGSER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_scaled = (train_input - mean) / std #표준점수로 반환한 학습데이터들"
      ],
      "metadata": {
        "id": "hjMM66J6IZ5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new = ([25,150] - mean) / std\n",
        "plt.scatter(train_scaled[:,0], train_scaled[:,1])\n",
        "plt.scatter(new[0],new[1], marker='^')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V51sB019Iw9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "무게와 길이의 scale이 비슷해졌다. 이제 knn 알고리즘을 적용하면.."
      ],
      "metadata": {
        "id": "FUjCUqjiJVBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kn.fit(train_scaled, train_target)\n",
        "test_scaled = (test_input - mean) / std\n",
        "kn.score(test_scaled, test_target) #1.0이 나왔다. 테스트 샘플을 완벽하게 분류한 것.\n",
        "\n",
        "print(kn.predict([new]))"
      ],
      "metadata": {
        "id": "UfxjzUL4JbE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distances,indexes = kn.kneighbors([new])\n",
        "plt.scatter(train_scaled[:,0], train_scaled[:,1])\n",
        "plt.scatter(new[0],new[1], marker='^')\n",
        "plt.scatter(train_scaled[indexes,0], train_scaled[indexes,1], marker='D')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E_mdIj71JtZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "특성 값의 스케일에 민감하지 않고 안정적인 예측을 할 수 있게 되었다.\n",
        "\n",
        "---\n",
        "\\\n",
        "\n",
        "###Summary\n",
        "\n",
        "데이터 전처리란 훈련 데이터를 넣기 전에 가공하는 단계를 말한다. 올바른 학습을 위해서는 필수적인 과정이다.\n",
        "\n",
        "표준점수는 훈련 데이터의 scale을 바꾸는 대표적인 방법 중 하나. 표준점수를 얻으려면 특성의 평균을 빼고 표준편차로 나눈다.\n",
        "\n",
        "**브로드캐스팅이란 크기가 다른 넘파이 배열에서 자동으로 사칙 연산을 모든 행이나 열로 확장하여 수행하는 기능이다.**\n"
      ],
      "metadata": {
        "id": "VIldgGuaKGsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\\\n",
        "##Chapter 3-1 회귀 알고리즘 / k-최근접 이웃 회귀"
      ],
      "metadata": {
        "id": "H-w1lPNwLQlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "회귀 regression\n",
        "\n",
        "지도학습은 크게 '분류'와 '회귀'로 나뉜다.\n",
        "\n",
        "분류는 말 그대로 샘플을 몇 개의 클래스 중 하나로 분류하는 문제이다.\n",
        "\n",
        "**'회귀'란 클래스 중 하나로 분류하는 것이 아니라 임의의 어떤 숫자를 예측하는 문제이다.** 예를 들면 내년 경제 성장률을 예측하거나, 배달이 도착할 시간을 예측하는 것이 회귀 문제이다."
      ],
      "metadata": {
        "id": "c1iWHaGvLc2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "k-최근접 알고리즘이 분류와 회귀에 적용되는 방식을 비교해보자.\n",
        "\n",
        "분류는 예측하려는 샘플에 가장 가까운 샘플 k개를 선택해서 다수 클래스를 새로운 클래스로 예측한다.\n",
        "\n",
        "\\\n",
        "\n",
        "k-최근접 이웃 회귀도 간단하다.샘플에 가장 가까운 샘플 k개를 선택한다. 하지만 회귀이기 때문에 어떤 클래스가 아닌 수치이다. 가장 간단한 방법은 평균을 때리기.\n"
      ],
      "metadata": {
        "id": "Xczbr1jACivI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 준비\n",
        "import numpy as np\n",
        "\n",
        "perch_length = np.array([8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0,\n",
        "       21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7,\n",
        "       23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5,\n",
        "       27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0,\n",
        "       39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5,\n",
        "       44.0])\n",
        "perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,\n",
        "       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,\n",
        "       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,\n",
        "       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,\n",
        "       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,\n",
        "       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,\n",
        "       1000.0])"
      ],
      "metadata": {
        "id": "hoau_8yvDmsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(perch_length, perch_weight)\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sv6TpwbXDyyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "농어의 길이가 늘어남에 따라 무게가 늘어나고 있다."
      ],
      "metadata": {
        "id": "Wt0K_labD9LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#훈련 세트와 테스트 세트로 나누기\n",
        "train_input, test_input, train_target, test_target = train_test_split(perch_length, perch_weight, random_state=42)\n",
        "\n",
        "#print(train_input.shape, test_input.shape)\n",
        "train_input"
      ],
      "metadata": {
        "id": "WxB2S8i7EMsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "사이킷런에 사용할 훈련 세트는 2차원 배열이여야 한다.\n",
        "\n",
        "그래서 1차원 배열을 1개의 열이 있는 2차원 배열로 만들어주어야 한다.\n",
        "**(42,) 에서 (42,1)로.**\n",
        "\n",
        "\\\n",
        "\n",
        "[1,2,3]은 크기가 (3,)이다. 파이썬에서 1차원 배열의 크기는 원소가 1개인 튜플로 나타낸다.\n",
        "\n",
        "우리는 이를 2차원 배열로 만들기 위해 억지로 하나의 열을 추가해주어야 한다.\n",
        "\n",
        "**이번 예제에서는 1개의 특성만을 활용하기에 수동으로 2차원 배열을 만들어주어야 한다.**\n",
        "\n",
        "reshape() 함수를 사용하는데 중요한 점은 사이즈에 유의하여야 한다는 점."
      ],
      "metadata": {
        "id": "QYQg1PMSF_jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input= train_input.reshape(-1,1)\n",
        "test_input = test_input.reshape(-1,1)\n",
        "\n",
        "print(train_input.shape,test_input.shape)"
      ],
      "metadata": {
        "id": "_gDT_SvJGZZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-1의 의미는 행의 개수는 너가 알아서 결정해라라는 의미이다.\n",
        "\n",
        "1은 1열을 가지도록 만들어주는 역할을 한다."
      ],
      "metadata": {
        "id": "atuG2_OmXlnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사이킷런에서 k-최근접 이웃 회귀 알고리즘을 구현한 클래스는 KNeighborsRegressor이다."
      ],
      "metadata": {
        "id": "FhGrZNMBYHDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "knr = KNeighborsRegressor()\n",
        "knr.fit(train_input, train_target)\n",
        "print(knr.score(test_input, test_target))"
      ],
      "metadata": {
        "id": "joUrvmKyYVVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "knr.score은 무엇일까??\n",
        "\n",
        "기존에 공부했던 분류의 경우 테스트 세트에서 정확하게 분류한 비율을 말한다.\n",
        "\n",
        "회귀에서는 정확한 숫자를 맞힌다는 것은 거의 불가능하다. 그래서 회귀의 경우 조금 다른 방식으로 평가를 한다. 바로 결정 계수라는 것이다.\n",
        "\n",
        "---\n",
        "\\\n",
        "\n",
        "### 결정계수 / 과적합&과소적합\n",
        "\n",
        "1. 결정계수\n",
        "\n",
        "$$R^2 = 1 - \\frac{\\text{SS}_{\\text{res}}}{\\text{SS}_{\\text{tot}}}$$\n",
        "\n",
        "각 샘플의 정답과 예측한 값의 차이를 제곱하여 더하기\n",
        "\n",
        "각 샘플의 정답과 정답 평균의 차이를 제곱하여 더하여 나누기\n",
        "\n",
        "예측이 정답에 아주 가까워지면 1에 가까운 값이 된다.\n",
        "\n",
        "\\\n",
        "\n",
        "정답과 예측한 값의 차이를 정확하게 봐보자."
      ],
      "metadata": {
        "id": "sM5Pev4AYa-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# 테스트 세트에 대한 예측을 만든다.\n",
        "test_prediction= knr.predict(test_input)\n",
        "\n",
        "# 테스트 세트에 대한 평균 절댓값 오차를 계산\n",
        "mae = mean_absolute_error(test_target, test_prediction)\n",
        "\n",
        "print(mae)"
      ],
      "metadata": {
        "id": "amwcHvfbaYEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측이 평균적으로 19g 정도 다르다는 것을 알 수 있다.\n",
        "\n",
        "\\\n",
        "\n",
        "2. 과대적합 & 과소적합\n",
        "\n",
        "모델은 훈련 세트에 잘 맞는 모델이 만들어진다. 보통은 train set에서 test set보다 높은 score이 나온다. 하지만 **만약 훈련 세트에서 점수가 좋았는데 테스트 세트에서 점수가 나쁘다면 overfitting**되었다고 말한다. 즉, 훈련세트에만 잘 맞는 모델이라 실전에 투입하여 잘 동작하지 않을 수 있다는 것이다.\n",
        "\n",
        "반면에 train set보다 test set 점수가 높거나 둘 다 낮은 경우는 underfitting되었다고 말한다. **즉, 모델이 너무 단순하여 훈련 세트에 적절히 훈련되지 않은 경우이다.**\n",
        "\n",
        "> ***그래서 우리는 훈련 세트가 전체 데이터를 대표한다고 가정하기 때문에 훈련 세트를 잘 학습시키는 것이 중요하다.***\n",
        "\n"
      ],
      "metadata": {
        "id": "vueN3IuJaxib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리가 실습한 예제는 과소적합에 해당한다. 모델을 좀 더 복잡하게 만들어 훈련 세트에 잘 맞게 만들면 테스트 점수는 조금 낮아질 것이다.\n",
        "\n",
        "knn이웃 회귀에서 복잡하게 만들려면 참조하는 이웃의 개수를 줄이면 된다. 그러면 국지적으로 더 민감해지게 된다.\n"
      ],
      "metadata": {
        "id": "92JEXivVeP47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knr.n_neighbors = 3\n",
        "\n",
        "knr.fit(train_input, train_target)\n",
        "print(knr.score(train_input, train_target))\n",
        "print(knr.score(test_input, test_target))"
      ],
      "metadata": {
        "id": "YUoHWCX0emcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\\\n",
        "\n",
        "### Summary\n",
        "회귀란 임의의 수치를 예측하는 문제이다. 그래서 정답값도 임의의 수치이다.\n",
        "\n",
        "k-최근접 이웃 회귀는 가장 가까운 이웃 샘플을 찾고 이 샘플들의 타깃값을 평균하여 예측으로 삼는다.\n",
        "\n",
        "\\\n",
        "\n",
        "overfitting: 훈련 세트에만 너무 치중되어 일반화하기 힘든 모델\n",
        "\n",
        "underfitting: 너무 단순하여 사용하기 적합하지 않은 상태.\n",
        "\n",
        "**우리는 최적의 모델을 만들기 위해 훈련 데이터를 적절하게 잘 학습시켜야 한다.**"
      ],
      "metadata": {
        "id": "I1rgEa9ze0c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mission: 과적합과 과소적합 이해를 위해 복잡한 모델과 단순한 모델 비교.\n",
        "\n",
        "knr = KNeighborsRegressor()\n",
        "\n",
        "x = np.arange(5, 45).reshape(-1,1)\n",
        "\n",
        "for n in [1, 5, 10]:\n",
        "  knr.n_neighbors = n\n",
        "  knr.fit(train_input, train_target)\n",
        "\n",
        "  prediction = knr.predict(x)\n",
        "\n",
        "  plt.scatter(train_input, train_target)\n",
        "  plt.plot(x, prediction)\n",
        "  plt.title('n_neighbors = {}'.format(n))\n",
        "  plt.xlabel('length')\n",
        "  plt.ylabel('weight')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "r4xM_AWifj1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plt.plot(x, prediction)으로 그려지는 선은 KNeighborsRegressor 모델이 n_neighbors 파라미터 값에 따라 입력 x에 대해 어떻게 예측 값을 생성하여 데이터의 패턴을 시각적으로 표현하는지를 나타낸다.\n",
        "\n",
        "각 x값에 대한 예측값."
      ],
      "metadata": {
        "id": "RPKa0HGTg8r0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\\\n",
        "\n",
        "## Chapter 3-2 선형 회귀(Linear Regression)"
      ],
      "metadata": {
        "id": "TXTvbZrqhIAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "k-최근접 이웃의 한계..\n",
        "\n",
        "데이터 준비를 해보자."
      ],
      "metadata": {
        "id": "2By3sXKehavX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "perch_length = np.array([8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0,\n",
        "       21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7,\n",
        "       23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5,\n",
        "       27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0,\n",
        "       39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5,\n",
        "       44.0])\n",
        "perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,\n",
        "       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,\n",
        "       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,\n",
        "       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,\n",
        "       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,\n",
        "       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,\n",
        "       1000.0])\n",
        "\n",
        "# 훈련 세트와 테스트 세트로 나누기 후 2차원 배열로 반환\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(perch_length, perch_weight, random_state=42)\n",
        "\n",
        "train_input = train_input.reshape(-1,1)\n",
        "test_input = test_input.reshape(-1,1)"
      ],
      "metadata": {
        "id": "iy4Jp7wLhhr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최근접 이웃 개수를 3으로 하는 모델 훈련.\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "knr = KNeighborsRegressor(n_neighbors=3)\n",
        "knr.fit(train_input, train_target)\n",
        "print(knr.predict([[50]])) #50cm의 농어의 무게를 예측"
      ],
      "metadata": {
        "id": "oHhWiEzRh_qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "distances, indexes = knr.kneighbors([[50]])\n",
        "\n",
        "plt.scatter(train_input, train_target)\n",
        "plt.scatter(train_input[indexes], train_target[indexes], marker='D') # 50dml 농어의 주변 이웃 3마리\n",
        "\n",
        "#50cm 농어 데이터\n",
        "plt.scatter(50, 1033, marker='^')\n",
        "plt.scatter(100, 1033, marker='^')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()\n",
        "\n",
        "#100cm 농어 데이터\n",
        "print(knr.predict([[100]]))"
      ],
      "metadata": {
        "id": "KpEYh2xciYAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**knn 최근접 이웃 알고리즘은 가장 가까운 데이터의 평균으로 예측하기 떄문에 45cm 근방의 농어들로 무게를 예측하게 된다.**\n",
        "\n",
        "**즉, 100cm의 농어를 plot 해봐도 1033g으로 예측하게 된다.**\n",
        "\n",
        "크기가 큰 농어가 포함되도록 훈련 세트를 다시 만들어야 한다...이는 너무 불편하다."
      ],
      "metadata": {
        "id": "U62tzOyuJ7KW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\\\n",
        "\n",
        "### 선형 회귀\n",
        "학습 데이터의 특성을 가장 잘 나타낼 수 있는 직선을 찾는 것이 선형 회귀.\n",
        "\n",
        "사이킷런의 LinearRegression 클래스로 선형 회귀 알고리즘을 구현할 수 있다."
      ],
      "metadata": {
        "id": "4FDCo6DgLLKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "\n",
        "lr.fit(train_input, train_target)\n",
        "\n",
        "print(lr.predict([[50]]))"
      ],
      "metadata": {
        "id": "_r4nLFcQL1Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터를 가장 잘 표현하는 직선의 방정식을 찾아 데이터에서 동떨어져 있어도 예측할 수 있게 된다.**"
      ],
      "metadata": {
        "id": "GFV3oUsCMGtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#직선의 방정식의 계수\n",
        "#기울기, y절편\n",
        "print(lr.coef_, lr.intercept_)"
      ],
      "metadata": {
        "id": "GPzZ0nrgMR0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **기울기와 절편을 머신러닝 알고리즘이 찾은 값이라는 의미로 모델 파라미터라고 부른다. 훈련의 과정은 최적의 모델 파라미터를 찾는 것과 같다.**\n"
      ],
      "metadata": {
        "id": "SflCtK5vMezO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(train_input,train_target)\n",
        "plt.plot([15,50],[15*lr.coef_+lr.intercept_, 50*lr.coef_+lr.intercept_])\n",
        "\n",
        "#50cm 농어 데이터\n",
        "plt.scatter(50,1241.8, marker='^')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1-E-BJjMMxW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.score(train_input, train_target)) #훈련 세트\n",
        "print(lr.score(test_input, test_target)) #테스트 세트"
      ],
      "metadata": {
        "id": "Qbb-C1_hNIc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 세트와 테스트 세트의 결정계수 R^2점수를 확인하면 위와 같은데 그렇게 높은 점수가 아니다. 그래프를 보면 오히려 데이터를 잘 대변하지 않음을 볼 수 있다.\n",
        "\n",
        "\\\n",
        "데이터를 대변하는 다항 회귀로 우리는 눈을 넓힐 수 있다.\n",
        "\n",
        "**2차 방정식의 그래프를 그리려면 길이를 제곱한 항이 훈련 세트에 추가되어야 한다.** 브로드캐스팅이 적용되어 모든 원소를 제곱한다. column_stack 함수를 적용하여 두 열을 나란히 붙이기."
      ],
      "metadata": {
        "id": "MkBXpCdbNZM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_poly = np.column_stack((train_input**2, train_input))\n",
        "test_poly = np.column_stack((test_input**2, test_input))\n",
        "\n",
        "print(train_poly.shape , test_poly.shape)"
      ],
      "metadata": {
        "id": "YP0j60sGNn3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**훈련 세트에 제곱항을 추가했지만, 타깃값인 정답값은 그대로 사용한다. 목표하는 값은 어떤 그래프를 훈련하든지 바꿀 필요가 없다.**"
      ],
      "metadata": {
        "id": "Pl6ZCIo0QksS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_2 = LinearRegression()\n",
        "lr_2.fit(train_poly, train_target)\n",
        "\n",
        "print(lr_2.predict([[50**2, 50]]))\n",
        "\n",
        "print(lr_2.coef_, lr_2.intercept_) #이차함수의 계수"
      ],
      "metadata": {
        "id": "LX5bwcphRAgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "point = np.arange(15,50)\n",
        "\n",
        "plt.scatter(train_input, train_target)\n",
        "plt.plot(point, 1.01*point**2 - 21.6*point + 116.05)\n",
        "plt.plot([15,50],[15*lr.coef_+lr.intercept_, 50*lr.coef_+lr.intercept_])\n",
        "\n",
        "#50cm 농어 데이터\n",
        "plt.scatter(50,1241.8, marker='^')\n",
        "plt.scatter(50,1574, marker='^')\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3jbANwolRo_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결정계수를 확인해보면.."
      ],
      "metadata": {
        "id": "nhs5YKerSQzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr_2.score(train_poly, train_target))\n",
        "print(lr_2.score(test_poly, test_target))"
      ],
      "metadata": {
        "id": "K7zOzCNWSWur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "여전히 테스트 세트의 점수가 높은 것을 볼 수 있다. **과소적합이 남아 있는 것...** 조금 더 복잡한 모델이 필요한 것."
      ],
      "metadata": {
        "id": "E5str7y2SZ-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\\\n",
        "\n",
        "### Summary\n",
        "훈련 데이터에서 떨어져 있는 데이터를 얘측하기 위해 훈련데이터를 잘 설명하는 다항식으로 우리는 회귀를 이용해야 한다.\n",
        "\n",
        "선형 회귀가 찾은 특성과 타깃 사이의 관계는 선형 방정식의 계수 또는 가중치에 저장된다. 이는 모델 파라미터이고 모델이 특성에서 학습한 파라미터를 의미하게 된다."
      ],
      "metadata": {
        "id": "visx__i7St-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\\n",
        "##Chapter3-3 여러 특성을 이용한 다중 회귀\n",
        "\n",
        "3-2에서는 하나의 특성을 이용하여 선형 회귀 모델을 학습시켰다. 여러 개의 특성을 사용한 선형 회귀를 다중 회귀라고 한다. 다중 회귀를 이용할 경우 여러 데이터를 참조하므로 학습률일 올라갈 수 있다."
      ],
      "metadata": {
        "id": "Eh6WsEPNX-Pi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2개의 특성을 사용하면 선형 회귀는 평면을 학습한다.\n",
        "\n",
        "![image](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTLcHZ13IjCjaSRLOVmb9PJni-GeVyDmoWTlw&s)\n",
        "\n",
        "**모델의 성능을 높이기 위해 기존의 특성을 이용해 새로운 특성을 뽑아내기도 한다. 이를 특성 공학이라고 한다.**\n",
        "\n",
        "\\\n",
        "\n",
        "데이터 준비를 해보자. 특성이 늘어났기 때문에 데이터를 복사해 붙여넣기 번거롭다. 판다스라는 유명한 데이터 분석 라이브러리를 사용해보자.\n",
        "\n",
        "> **판다스를 이용해 농어 데이터를 인터넷에서 받아 데이터프레임에 저장하고 넘파이 배열로 변환하여 선형 회귀 모델을 훈련해 보자. 판다스 데이터프레임을 만들기 위해 csv를 많이 쓴다.**"
      ],
      "metadata": {
        "id": "reNRkCX3Yd6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 준비\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://bit.ly/perch_csv_data')\n",
        "\n",
        "perch_full = df.to_numpy()\n",
        "print(perch_full)\n",
        "\n",
        "#타깃 데이터\n",
        "import numpy as np\n",
        "\n",
        "perch_length = np.array([8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0,\n",
        "       21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7,\n",
        "       23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5,\n",
        "       27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0,\n",
        "       39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5,\n",
        "       44.0])\n",
        "perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,\n",
        "       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,\n",
        "       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,\n",
        "       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,\n",
        "       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,\n",
        "       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,\n",
        "       1000.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hh67JqgZl36",
        "outputId": "200050fc-a61a-43e1-ab56-888be2f18c29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8.4   2.11  1.41]\n",
            " [13.7   3.53  2.  ]\n",
            " [15.    3.82  2.43]\n",
            " [16.2   4.59  2.63]\n",
            " [17.4   4.59  2.94]\n",
            " [18.    5.22  3.32]\n",
            " [18.7   5.2   3.12]\n",
            " [19.    5.64  3.05]\n",
            " [19.6   5.14  3.04]\n",
            " [20.    5.08  2.77]\n",
            " [21.    5.69  3.56]\n",
            " [21.    5.92  3.31]\n",
            " [21.    5.69  3.67]\n",
            " [21.3   6.38  3.53]\n",
            " [22.    6.11  3.41]\n",
            " [22.    5.64  3.52]\n",
            " [22.    6.11  3.52]\n",
            " [22.    5.88  3.52]\n",
            " [22.    5.52  4.  ]\n",
            " [22.5   5.86  3.62]\n",
            " [22.5   6.79  3.62]\n",
            " [22.7   5.95  3.63]\n",
            " [23.    5.22  3.63]\n",
            " [23.5   6.28  3.72]\n",
            " [24.    7.29  3.72]\n",
            " [24.    6.38  3.82]\n",
            " [24.6   6.73  4.17]\n",
            " [25.    6.44  3.68]\n",
            " [25.6   6.56  4.24]\n",
            " [26.5   7.17  4.14]\n",
            " [27.3   8.32  5.14]\n",
            " [27.5   7.17  4.34]\n",
            " [27.5   7.05  4.34]\n",
            " [27.5   7.28  4.57]\n",
            " [28.    7.82  4.2 ]\n",
            " [28.7   7.59  4.64]\n",
            " [30.    7.62  4.77]\n",
            " [32.8  10.03  6.02]\n",
            " [34.5  10.26  6.39]\n",
            " [35.   11.49  7.8 ]\n",
            " [36.5  10.88  6.86]\n",
            " [36.   10.61  6.74]\n",
            " [37.   10.84  6.26]\n",
            " [37.   10.57  6.37]\n",
            " [39.   11.14  7.49]\n",
            " [39.   11.14  6.  ]\n",
            " [39.   12.43  7.35]\n",
            " [40.   11.93  7.11]\n",
            " [40.   11.73  7.22]\n",
            " [40.   12.38  7.46]\n",
            " [40.   11.14  6.63]\n",
            " [42.   12.8   6.87]\n",
            " [43.   11.93  7.28]\n",
            " [43.   12.51  7.42]\n",
            " [43.5  12.6   8.14]\n",
            " [44.   12.49  7.6 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perch_full과 perch_weight를 훈련 세트와 테스트 세트로 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(perch_full, perch_weight, random_state=42)"
      ],
      "metadata": {
        "id": "KVt0j_8Waw_5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 데이터들을 이용해서 **새로운 특성**을 만들어보자.\n",
        "\n",
        "\\\n",
        "\n",
        "사이킷런에서는 특성을 만들거나 전처리하기 위해 다양한 클래스를 제공하는데 이를 **transformer(변환기)**이라고 한다. 앞서 사용했던 LinearRegression 같은 클래스는 추정기라고 불린다.\n",
        "\n",
        "**이번 챕터에서 사용할 변환기는 PolynomialFeatures 클래스.**\n"
      ],
      "metadata": {
        "id": "QWtx-yKYa-0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures()\n",
        "poly.fit([[2,3]])\n",
        "print(poly.transform([[2,3]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3Lf_Lo5gXvx",
        "outputId": "e916f46e-530b-4c1a-b67a-1c0fffccf135"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 2. 3. 4. 6. 9.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fit()메소드는 새롭게 만들 특성 조합을 찾고 transform() 함수는 실제로 데이터를 변환한다. 변환기는 입력 데이터를 변환하는데 타깃 데이터가 필요하지 않다. 그래서 fit() 함수에 입력 데이터만 전달.\n",
        "\n",
        "PolynomialFeatures 클래스는 기본적으로 각 특성을 제곱한 항을 추가하고 특성끼리 곱한 항을 추가.\n",
        "\n",
        "$${무게 = a*길이 + b*높이 + c*두께 + d*1}$$\n",
        "절편을 항상 값이 1인 특성과 곱해지는 계수라고 볼 수 있어서 1이 추가된다. 특성은 (길이,높이,두께,1). 하지만 사이킷런 모델은 자동으로 절편을 추가하므로 굳이 특성을 이렇게 만들 필요가 없다.\n",
        "\n",
        "\\\n",
        "\n",
        "**이제 이 방식으로 train_input에 적용해보자.** train_input을 변환한 데이터를 train_poly에 저장하고 배열의 크기를 확인헤보자."
      ],
      "metadata": {
        "id": "Yt4SDeZcgqBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(include_bias=False)\n",
        "poly.fit(train_input)\n",
        "train_poly = poly.transform(train_input)\n",
        "\n",
        "print(train_poly.shape)\n",
        "\n",
        "poly.get_feature_names_out()"
      ],
      "metadata": {
        "id": "93KoJo1-iADm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4206a6d-4907-4abf-f945-c7686bcc3710"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['x0', 'x1', 'x2', 'x0^2', 'x0 x1', 'x0 x2', 'x1^2', 'x1 x2',\n",
              "       'x2^2'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "x0은 첫번째 특성을 의미하고 특성을 조합하여 새로운 특성을 만드는 것을 볼 수 있다.\n",
        "\n",
        "이제 테스트 세트를 변환"
      ],
      "metadata": {
        "id": "0UT-TL-vRXFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_poly = poly.transform(test_input)"
      ],
      "metadata": {
        "id": "nA9_rXDVRjCV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "###다중회귀 모델 훈련하기\n",
        "다중 회귀 모델을 훈련하는 것은 선형 회귀 모델을 훈련하는 것과 같다. 다만, 여러 개의 특성을 사용하여 선형 회귀를 수행하는 것일 뿐이다."
      ],
      "metadata": {
        "id": "qKLN0EqNRr1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(train_poly, train_target)\n",
        "print(lr.score(train_poly, train_target))\n",
        "print(lr.score(test_poly, test_target)) # 과소적합이 더이상 일어나지 않는다."
      ],
      "metadata": {
        "id": "0hULUggeSFVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afc573cf-9230-4753-f6c3-ed612fd4b1ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9903183436982125\n",
            "0.9714559911594111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **농어의 길이 뿐만이 아니라 높이와 두께를 모두 사용했고 각 특성을 제곱하거나 서로 곱해서 다항 특성을 더 추가했다. 특성이 늘어나면 선형 회귀의 능력은 매우 강하다는 것을 알 수 있다.**"
      ],
      "metadata": {
        "id": "YK6umJaBSSz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#특성을 더 많이 늘려보자...\n",
        "poly = PolynomialFeatures(degree=5, include_bias=False)\n",
        "poly.fit(train_input)\n",
        "train_poly = poly.transform(train_input)\n",
        "test_poly = poly.transform(test_input)\n",
        "\n",
        "print(train_poly.shape) #특성의 개수가 55개\n",
        "\n",
        "lr.fit(train_poly, train_target)\n",
        "print(lr.score(train_poly, train_target))\n",
        "print(lr.score(test_poly, test_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCnhqZufS48I",
        "outputId": "de18e973-df91-46f1-9507-0864fab18fde"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42, 55)\n",
            "0.9999999999996433\n",
            "-144.40579436844948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 세트에 대한 점수가 매우매우 높지만 테스트 세트에 대한 점수가 음수가 되었다.\n",
        "\n",
        "> **특성의 개수를 늘리면 선형 모델은 매우 강력해지지만, 이런 모델은 훈련 세트에 너무 과적합되어 테스트 세트에서는 형편없는 점수를 만들어 낸다.**\n",
        "\n",
        "\\\n",
        "\n",
        "---\n",
        "###과적합을 줄이는 방법... Regularization 정규화\n",
        "정규화(규제)란 머신러닝 모델이 훈련 세트를 너무 과도하게 학습하지 못하도록 훼방하는 것을 말한다. 즉, 모델이 훈련 세트에 과적합되지 않도록 만드는 것이다.\n",
        "\n",
        "선형 회귀 모델에서 정규화는 특성에 곱해지는 계수의 크기를 작게 만드는 일.\n"
      ],
      "metadata": {
        "id": "Bqa31iCLTKLb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GCB4UkgdUXaO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}